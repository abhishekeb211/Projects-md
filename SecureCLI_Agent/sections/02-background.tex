% Section 2: Background
% Converted from 4.2-background.md
% Module 5.2: Section Integration & Flow Refinement

\subsection{SARIF: Static Analysis Results Interchange Format}

The \textbf{Static Analysis Results Interchange Format (\sarif{})} is an OASIS standard (version 2.1.0) that defines a JSON schema for representing security findings from static analysis tools, enabling interoperability across scanners and downstream analysis systems. \sarif{} addresses the fragmentation problem in security tooling by providing a unified data model for findings, rules, locations, and result metadata.

A \sarif{} result object represents a single security finding and includes the following key properties:

\begin{verbatim}
{
  "ruleId": "java/insecure-random",
  "level": "error",
  "message": {
    "text": "Use of java.util.Random is insecure; prefer SecureRandom"
  },
  "locations": [{
    "physicalLocation": {
      "artifactLocation": {
        "uri": "src/main/java/App.java"
      },
      "region": {
        "startLine": 42,
        "startColumn": 12,
        "endLine": 42,
        "endColumn": 28
      }
    }
  }],
  "rule": {
    "id": "java/insecure-random",
    "name": "Insecure Random Number Generation",
    "shortDescription": {
      "text": "Detects insecure RNG usage"
    },
    "properties": {
      "cwe": ["CWE-330"],
      "severity": "high"
    }
  }
}
\end{verbatim}

\sarif{} enables cross-tool deduplication (multiple scanners detecting the same vulnerability), consistent severity mapping (normalizing CRITICAL/HIGH/MEDIUM/LOW across tools), and unified reporting dashboards that aggregate findings from diverse scanner ecosystems. GitHub, GitLab, and Azure DevOps have adopted \sarif{} as the standard format for security findings ingestion, making it a de facto industry standard for security tool interoperability~\cite{ref:smith2020}.

However, \sarif{} adoption remains incomplete: some scanners (e.g., OWASP ZAP for \dast{}) produce partial \sarif{} output, and runtime security tools (\sast{} vs. \dast{}) require different schema extensions, limiting full orchestration coverage. AegisCLI addresses these gaps by implementing \sarif{} v2.1.0 normalization with custom extensions for finding confidence scores, policy decision flags, and champion review annotations.

\subsection{OPA/Rego: Policy-as-Code Framework}

\textbf{Open Policy Agent (\opa{})} is an open-source policy engine that enables policy-as-code (\pac{}) by encoding security rules, compliance requirements, and remediation SLAs as executable Rego policies. Rego, \opa{}'s declarative policy language, provides a unified interface for policy evaluation across diverse contexts (infrastructure-as-code, API authorization, security finding triage).

A Rego policy example for blocking secrets in Terraform infrastructure-as-code:

\begin{verbatim}
package aegiscli.policies

default allow = false

# Block secrets in Terraform variables
deny[msg] {
    input.kind == "terraform"
    input.ruleId == "secrets-in-code"
    contains(input.code, "password") 
    contains(input.code, "=")
    msg := "Terraform variable contains password literal; use secrets manager"
}

# Allow exemptions with security-champion approval
allow {
    input.exemptions[_] == "champion-approved"
}
\end{verbatim}

\opa{} evaluates policies against structured input data (e.g., \sarif{} findings) and returns allow/deny decisions with explanatory messages, enabling automated policy enforcement without manual review for standard cases. AegisCLI integrates \opa{} as the policy engine for remediation workflows, encoding rules such as ``critical findings must be remediated within 48 hours'' or ``low-severity findings can be suppressed if confirmed false-positive by \llm{} triage (confidence $\geq$ 0.8)''.

Rego policies are declarative (describing \textit{what} should be enforced, not \textit{how}), composable (policies can be combined into bundles), and auditable (policy changes are version-controlled and reviewable). This makes \opa{} suitable for compliance-driven organizations that require policy transparency, version control, and automated enforcement~\cite{ref:opa2023}.

\subsection{ST-SSDLC: Socio-Technical Secure Software Development Lifecycle}

The \textbf{Socio-Technical Secure Software Development Lifecycle (ST-SSDLC)} framework, introduced by Farnsworth (2021), extends traditional secure SDLC models by explicitly modeling the interaction between technical security controls and organizational factors (team culture, champion programs, tool adoption friction)~\cite{ref:farnsworth2021}. ST-SSDLC recognizes that security tool effectiveness depends not only on technical accuracy (finding true positives) but also on socio-technical enablers (developer acceptance, security champion advocacy, organizational policy alignment).

ST-SSDLC identifies three critical dimensions: \textbf{Technical}: security tools, automation pipelines, \pac{} enforcement; \textbf{Organizational}: security culture, champion programs, compliance requirements; \textbf{Behavioral}: developer tool adoption, \mttr{} responsiveness, security debt management practices. The framework predicts that successful DevSecOps adoption requires alignment across all three dimensions---introducing advanced security tools without corresponding organizational support (champions, training) or behavioral change (developer workflow integration) leads to low adoption and persistent security debt.

AegisCLI's design reflects ST-SSDLC principles: the platform addresses technical orchestration (\sarif{} normalization), organizational support (champion program integration via policy exemptions), and behavioral adaptation (developer-friendly unified interface, reduced tool-switching overhead). Our evaluation (Section 6) explicitly measures outcomes across these dimensions, validating ST-SSDLC predictions and extending the framework to incorporate local-first AI as a privacy-preserving automation mechanism.

\subsection{Local LLMs vs. Cloud LLMs: Privacy and Performance Tradeoffs}

Large Language Models (\llm s) have demonstrated promising capabilities for security analysis tasks, including vulnerability classification, false-positive reduction, and code review assistance. However, \llm{} deployment architectures create a fundamental tension between \textbf{privacy} (data residency, air-gap requirements) and \textbf{performance} (model size, inference latency, accuracy).

\textbf{Cloud-hosted \llm s} (GPT-4, Claude, GitHub Copilot) offer superior accuracy (reported $\kappa > 0.85$ for security triage) and convenience (no local infrastructure, automatic updates), but require transmitting code snippets and security findings to external providers, violating data residency constraints for regulated industries (defense, healthcare, finance). Regulatory frameworks (GDPR Article 44, HIPAA BAA requirements, PCI-DSS) often prohibit or restrict cloud-based processing of sensitive codebases, forcing organizations into suboptimal manual workflows.

\textbf{Local \llm s} (CodeLlama 13B, Mistral 7B, deployed via Ollama) address privacy constraints by running entirely on-premises, eliminating code exfiltration risks, but introduce performance tradeoffs: quantized models (Q4\_K\_M) may achieve lower accuracy ($\kappa \approx 0.75$--$0.80$) compared to cloud models, require GPU infrastructure (or slower CPU inference), and necessitate model management overhead (downloading, updating, versioning). Zhang (2024) provides a comparative analysis of local vs. cloud \llm s for code analysis tasks, demonstrating that quantized local models can achieve acceptable accuracy (within 5\% of cloud baselines) while preserving privacy~\cite{ref:zhang2024}.

AegisCLI adopts a local-first \llm{} architecture (CodeLlama 13B via Ollama, Q4\_K\_M quantization) to enable privacy-preserving security automation in air-gapped environments. Our evaluation (RQ2, Section 6.2) validates that local \llm{} triage achieves acceptable accuracy ($\kappa = 0.78$) compared to expert panels, demonstrating the viability of this tradeoff for privacy-sensitive organizations. The platform supports optional cloud \llm{} fallback (via API) for non-regulated contexts, allowing organizations to choose the appropriate privacy-performance balance for their regulatory requirements.

% Transition paragraph to Section 3 (Related Work)
Having reviewed the foundational technologies (\sarif{}, \opa{}/\pac{}, ST-SSDLC, local \llm s), the next section positions our work within the broader research landscape on scanner orchestration, AI-powered security analysis, and DevSecOps adoption.

